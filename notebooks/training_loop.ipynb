{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_loop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "d8F5tl4NL7FZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kernel setup"
      ],
      "metadata": {
        "id": "Rwo44VGZLhAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "hKuFzk7aEmB9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "!git clone https://github.com/Krankile/npmf.git"
      ],
      "metadata": {
        "id": "91KPY7q0LUOw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "gUXnibj8YEi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54965ee7-4654-4453-c392-9ea9f47706fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##General setup"
      ],
      "metadata": {
        "id": "CLAlA0htLgMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!cd npmf && git pull\n",
        "\n",
        "import math\n",
        "import multiprocessing\n",
        "import os\n",
        "import pickle\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import asdict, dataclass\n",
        "from datetime import datetime, timedelta\n",
        "from operator import itemgetter\n",
        "from typing import Callable, List, Tuple\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from npmf.utils.colors import main, main2, main3\n",
        "from npmf.utils.dataset import TimeDeltaDataset\n",
        "from npmf.utils.dtypes import fundamental_types\n",
        "from npmf.utils.eikon import column_mapping\n",
        "from npmf.utils.tests import pickle_df\n",
        "from npmf.utils.wandb import get_dataset, put_dataset\n",
        "from numpy.ma.core import outerproduct\n",
        "from pandas.tseries.offsets import BDay, Day\n",
        "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import wandb as wb"
      ],
      "metadata": {
        "id": "1QSlgObXLq1p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[main, main2, main3, \"black\"])\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)  # (6, 4) is default and used in the paper"
      ],
      "metadata": {
        "id": "hkTjKKLmLvpl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqy02oAvY7GM",
        "outputId": "8e2ef7ba-c8aa-401e-f096-43ac37ea0a7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(69)"
      ],
      "metadata": {
        "id": "YVFtfDk0pYtd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Neural network class"
      ],
      "metadata": {
        "id": "qM4PhINrGVa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get some data"
      ],
      "metadata": {
        "id": "PGuFgO6jHPWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "stock_df = get_dataset(\"stock-oil-final:latest\", project=\"master-test\")\n",
        "fundamentals_df = get_dataset(\"fundamentals-oil-final:latest\", project=\"master-test\")\n",
        "meta_df = get_dataset(\"meta-oil-final:latest\", project=\"master-test\")\n",
        "macro_df = get_dataset(\"macro-oil-final:latest\", project=\"master-test\")\n",
        "\n",
        "stock_df = stock_df.drop_duplicates(subset=[\"ticker\", \"date\"])"
      ],
      "metadata": {
        "id": "GHmOVxnnHYU_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the loop! (Like Odd-Geir Lademo)"
      ],
      "metadata": {
        "id": "s5zbIHNQHUNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?id=1Y55gFQSi4Baovmi0kUQGhbgGOBTI03E7)\n"
      ],
      "metadata": {
        "id": "tA8fn-daswS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateNetwork(nn.Module):\n",
        "    def __init__(self, lag_len, meta_cont_len, meta_cat_len, macro_len, hidden_dim, out_len, **params):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lags = nn.Sequential(\n",
        "            nn.Linear(lag_len, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.meta_cont = nn.Sequential(\n",
        "            nn.Linear(meta_cont_len, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.meta_cat = [nn.Embedding(l, hidden_dim) for l in meta_cat_len]\n",
        "\n",
        "        self.macro = nn.Sequential(\n",
        "            nn.Linear(macro_len, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(3*hidden_dim + 9*hidden_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, out_len),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, lags, meta_cont, meta_cat, macro):\n",
        "\n",
        "        lags = self.lags(lags)\n",
        "        meta_cont = self.meta_cont(meta_cont)\n",
        "        meta_cat = torch.cat([emb(meta_cat[:, i]) for i, emb in enumerate(self.meta_cat)], dim=1)\n",
        "        macro = self.macro(macro)\n",
        "\n",
        "        x = torch.cat((lags, meta_cont, meta_cat, macro), dim=1)\n",
        "        x = self.predict(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "jKqMY62PGZzj"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mape_loss(target, y_pred):\n",
        "    mask = ~target.isnan()\n",
        "    denom = mask.sum(dim=1)\n",
        "    target[target != target] = 0\n",
        "    l = ((((y_pred - target).abs() / (target.abs() + 1e-8) * mask)).sum(dim=1) / denom).mean()\n",
        "    return l"
      ],
      "metadata": {
        "id": "tAcXcNVq3jkY"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class RunParams:\n",
        "    n_reports: int\n",
        "    training_w: int\n",
        "    forecast_w: int\n",
        "    epochs: int\n",
        "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
        "\n",
        "    lag_len: int\n",
        "    meta_cont_len: int\n",
        "    meta_cat_len: List[int]\n",
        "    macro_len: int\n",
        "    out_len: int\n",
        "    hidden_dim: int\n",
        "    batch_size: int"
      ],
      "metadata": {
        "id": "DKFFb26068ZG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, data_train, data_val, device, params: RunParams, pbar):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    postfix = dict()\n",
        "    for epoch in range(params.epochs):\n",
        "        postfix = {**postfix, \"epoch\": epoch}\n",
        "        pbar.set_postfix(postfix)\n",
        "        for run_type, dataloader in {\"train\": data_train, \"val\": data_val}.items():\n",
        "            model.train(run_type == \"train\")\n",
        "            \n",
        "            for stocks_and_fundamentals, meta_cont, meta_cat, macro, target in dataloader:\n",
        "                optimizer.zero_grad()\n",
        "                stocks_and_fundamentals = stocks_and_fundamentals.to(torch.float).to(device)\n",
        "                meta_cont = meta_cont.to(torch.float).to(device)\n",
        "                meta_cat = meta_cat.to(torch.long).to(device)\n",
        "                macro = macro.to(torch.float).to(device)\n",
        "                target = target.to(torch.float).to(device)\n",
        "\n",
        "                y_pred = model(stocks_and_fundamentals, meta_cont, meta_cat, macro)\n",
        "    \n",
        "                loss = params.loss_fn(target, y_pred)\n",
        "\n",
        "                if run_type == \"train\":\n",
        "                    train_losses.append(loss.item())\n",
        "                    loss.backward()\n",
        "\n",
        "                    optimizer.step()\n",
        "                else:\n",
        "                    val_losses.append(loss.item())\n",
        "        postfix = {**postfix, \"train_loss\": np.mean(train_losses), \"val_loss\": np.mean(val_losses)}\n",
        "        pbar.set_postfix(postfix)\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "lRHUgmiYTrC-"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    params = RunParams(\n",
        "        n_reports=4,\n",
        "        training_w=240,\n",
        "        forecast_w=20,\n",
        "        epochs=10,\n",
        "        loss_fn=mape_loss,\n",
        "        lag_len=302,\n",
        "        meta_cont_len=1,\n",
        "        meta_cat_len=np.array([89, 5, 70, 185, 1, 3, 5, 10, 44]) + 1, \n",
        "        macro_len=1920,\n",
        "        out_len=20,\n",
        "        hidden_dim=32,\n",
        "        batch_size=64,\n",
        "    )\n",
        "\n",
        "    cpus = multiprocessing.cpu_count()\n",
        "    cpus = 0\n",
        "\n",
        "    model = MultivariateNetwork(**asdict(params))\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "    date_range = pd.date_range(start=\"2000-12-31\", end=\"2018-10-31\", freq=\"M\")\n",
        "    n_ranges = len(date_range)\n",
        "    periods = iter(date_range)\n",
        "    tra = None\n",
        "    period = next(periods)\n",
        "\n",
        "    val = TimeDeltaDataset(period, params.training_w, params.forecast_w, params.n_reports, stock_df, fundamentals_df, meta_df, macro_df)\n",
        "\n",
        "    outer = tqdm(periods, total=(n_ranges-1), desc=f\"Period {period.date()}\", leave=True, position=0)\n",
        "\n",
        "    for period in outer:\n",
        "        outer.set_description(f\"Period {period.date()}\")\n",
        "        tra = val\n",
        "        # TODO Refactor this class to only require the top-level params once\n",
        "        val = TimeDeltaDataset(period, params.training_w, params.forecast_w, params.n_reports, stock_df, fundamentals_df, meta_df, macro_df)\n",
        "\n",
        "        tra_loader = DataLoader(tra, params.batch_size, shuffle=True, drop_last=True, num_workers=cpus)\n",
        "        val_loader = DataLoader(val, params.batch_size, shuffle=False, num_workers=cpus)\n",
        "\n",
        "        train(model, optimizer, tra_loader, val_loader, device, params, pbar=outer)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvhDBuuccqfr",
        "outputId": "64cc5b91-d407-4852-c8fd-4761389a4f14"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Period 2018-10-31: 100%|██████████| 214/214 [33:16<00:00,  9.33s/it, epoch=9, train_loss=0.103, val_loss=0.113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    "
      ],
      "metadata": {
        "id": "Zly64VEmlwGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xIxAVNdcMTY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}