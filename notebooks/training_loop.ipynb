{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8F5tl4NL7FZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwo44VGZLhAo"
      },
      "source": [
        "## Kernel setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hKuFzk7aEmB9"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "91KPY7q0LUOw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb more_itertools\n",
        "!git clone https://github.com/Krankile/npmf.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUXnibj8YEi1",
        "outputId": "a3e62522-b0a1-4401-a307-95860ba7df02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "# https://wandb.ai/authorize\n",
        "!wandb login 52f9674a6dd8b8c5e456e0c788014f12ebb9cd90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLAlA0htLgMY"
      },
      "source": [
        "## General setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1QSlgObXLq1p"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!cd npmf && git pull\n",
        "\n",
        "import math\n",
        "import multiprocessing\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import asdict, dataclass\n",
        "from datetime import datetime, timedelta\n",
        "from operator import itemgetter\n",
        "from typing import Callable, List, Tuple\n",
        "from functools import partial\n",
        "from glob import glob\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "\n",
        "from more_itertools import chunked\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from npmf.utils import Problem\n",
        "from npmf.utils.colors import main, main2, main3\n",
        "from npmf.utils.dataset import EraDataset, EraController\n",
        "from npmf.utils.dataset.utils import clamp_and_slice\n",
        "from npmf.utils.dtypes import fundamental_types\n",
        "from npmf.utils.eikon import column_mapping\n",
        "from npmf.utils.tests.utils import pickle_df\n",
        "from npmf.utils.wandb import get_datasets, put_dataset, put_nn_model, get_processed_data\n",
        "from npmf.utils.training import EarlyStop, to_device, TqdmPostFix, loss_fns, get_naive_pred, activations\n",
        "from npmf.utils.models import models\n",
        "\n",
        "from numpy.ma.core import outerproduct\n",
        "from pandas.tseries.offsets import BDay, Day\n",
        "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "\n",
        "import wandb as wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hkTjKKLmLvpl"
      },
      "outputs": [],
      "source": [
        "np.seterr(all=\"raise\")\n",
        "\n",
        "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[main, main2, main3, \"black\"])\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)  # (6, 4) is default and used in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dqy02oAvY7GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d62181-b247-4dc8-91ff-d76bb75a4478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cy50qmXr5_8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bfcb78-9ddc-4346-f54f-b8353349e549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 10 09:00:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YVFtfDk0pYtd"
      },
      "outputs": [],
      "source": [
        "pre_proc_data_dir = None\n",
        "np.random.seed(69)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGuFgO6jHPWX"
      },
      "source": [
        "\n",
        "# Get some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4GW-peR9fUqa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "reload_data = not True\n",
        "\n",
        "if reload_data or not \"stock_df\" in vars():\n",
        "    names = [\"stock-data:final\", \"fundamental-data:final\", \"meta-data:final\", \"macro-data:final\"]\n",
        "\n",
        "    stock_df, fundamental_df, meta_df, macro_df = get_datasets(names=names, project=\"master\")\n",
        "\n",
        "    stock_df = stock_df.drop(columns=[\"close_price\", \"currency\"]).astype({\"market_cap\": np.float32})\n",
        "    fundamental_df = fundamental_df.drop(columns=\"period_end_date\").astype(fundamental_types)\n",
        "    macro_df.iloc[:, 1:] = macro_df.iloc[:, 1:].astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKB0ueURvYVp"
      },
      "source": [
        "# Create the loop! (Like Hans Gude Gudesen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pZAHVCqKuIOb"
      },
      "outputs": [],
      "source": [
        "# Check if it's necessary to calculate naive loss every epoch\n",
        "def get_epoch_loss(model, optimizer, dataloader, loss_fn, device, run_type, conf) -> Tuple[np.array, np.array, np.array]:\n",
        "    model_losses = []\n",
        "    naive_losses = []\n",
        "    y_preds = []\n",
        "    for data, meta_cont, meta_cat, target in to_device(dataloader, device):\n",
        "        if run_type == \"train\":\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            naive_pred = get_naive_pred(data, target, device, conf)\n",
        "            naive_loss = loss_fn(target.clone(), naive_pred)\n",
        "\n",
        "        y_pred: torch.Tensor = model(data, meta_cont, meta_cat)\n",
        "        loss = loss_fn(target, y_pred)\n",
        "        \n",
        "        model_losses.append(loss.item())\n",
        "        naive_losses.append(naive_loss.item())\n",
        "        y_preds.append(y_pred.detach().cpu().numpy())\n",
        "\n",
        "        if run_type == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model_losses, naive_losses, np.concatenate(y_preds, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g3bvK3f9iHmo"
      },
      "outputs": [],
      "source": [
        "def eras_ahead_loss(model, data_loaders, conf):\n",
        "    model_infront = []\n",
        "    naive_infront = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for loader in data_loaders:\n",
        "            model_loss, naive_loss, _ = get_epoch_loss(model, None, loader, loss_fns[conf.val_loss], device, \"inference\", conf)\n",
        "        \n",
        "            model_infront += model_loss\n",
        "            naive_infront += naive_loss\n",
        "    \n",
        "    return np.array(model_infront), np.array(naive_infront)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lRHUgmiYTrC-"
      },
      "outputs": [],
      "source": [
        "def train_one_era(run, model, optimizer, data_train, data_val, stopper, losses, device, conf, pbar):\n",
        "\n",
        "    for epoch in range(conf.max_epochs):\n",
        "        epoch_losses = dict(train=[], val=[])\n",
        "        \n",
        "        pbar.update_postfix({\"epoch\": epoch})\n",
        "        for run_type, dataloader in {\"train\": data_train, \"val\": data_val}.items():\n",
        "            model.train(run_type == \"train\")\n",
        "            \n",
        "            epoch_model_loss, naive_losses, y_preds = get_epoch_loss(model, optimizer, dataloader, loss_fns[conf[f\"{run_type}_loss\"]], device, run_type, conf)\n",
        "            epoch_losses[run_type] += epoch_model_loss\n",
        "\n",
        "            epoch_loss = np.mean(epoch_losses[run_type])\n",
        "            losses[run_type].append(epoch_loss)\n",
        "\n",
        "            run.log({f\"epoch_{run_type}\": epoch_loss, \"epoch\": epoch, \"ticker_var\": y_preds.std(axis=0).mean(), \"self_var\": y_preds.std(axis=1).mean()})\n",
        "\n",
        "        pbar.update_postfix({\"train_loss\": np.mean(epoch_losses[\"train\"]), \"val_loss\": np.mean(epoch_losses[\"val\"]), \"naive\": np.mean(naive_losses)})\n",
        "\n",
        "        # TODO: Implement checkpointing of the best model according to val_loss\n",
        "        if run_type == \"val\" and stopper(epoch_losses[\"val\"]):\n",
        "            losses[\"epoch_lens\"].append(epoch + 1)\n",
        "            break\n",
        "\n",
        "    return epoch_losses[\"train\"], epoch_losses[\"val\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(eras, model, train_losses, val_losses, i, run, conf, pbar):\n",
        "    loaders_infront, loaders_end = eras.validation_loaders()\n",
        "    model_infront, naive_infront = eras_ahead_loss(model, loaders_infront, conf)\n",
        "    model_end, naive_end = eras_ahead_loss(model, loaders_end, conf)\n",
        "\n",
        "    metric_loss = 0.5*(np.mean(model_infront/(naive_infront+1e-6)-1) + np.mean(model_end/(naive_end+1e-6)-1))\n",
        "\n",
        "    run.log({\"era_train\": np.mean(train_losses), \"era_val\" : np.mean(val_losses),\"model_infront\": np.mean(model_infront),\n",
        "            \"naive_infront\": np.mean(naive_infront), \"model_end\": np.mean(model_end), \"naive_end\": np.mean(naive_end),\n",
        "            \"metric_loss\": metric_loss, \"time\": eras.date.timestamp(), \"era\": i})\n",
        "\n",
        "    pbar.update_postfix(dict(metric_loss=metric_loss))\n",
        "\n",
        "    return metric_loss"
      ],
      "metadata": {
        "id": "4B37VcZmDUX5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sOlLqBTsMW1G"
      },
      "outputs": [],
      "source": [
        "def train(config, project=None, entity=None, enablewb=True) -> nn.Module:\n",
        "    \n",
        "    mode = \"online\" if enablewb else \"disabled\"\n",
        "    with wb.init(config=config, project=project, entity=entity, job_type=\"training\", mode=mode) as run:\n",
        "        best_metric = float(\"inf\")\n",
        "        best_wts = None\n",
        "        conf = run.config\n",
        "        print(conf)\n",
        "\n",
        "        pre_proc_data_dir = None\n",
        "        if conf.use_pre_proc_data:\n",
        "            pre_proc_data_dir = get_processed_data(run, conf=conf)\n",
        "\n",
        "        run.config.update(dict(pre_proc_data_dir=pre_proc_data_dir))\n",
        "        conf = run.config\n",
        "        \n",
        "        model: nn.Module = models[conf.model](**conf).to(device)\n",
        "\n",
        "        # Try decreasing learning rate underway\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=conf.learning_rate)\n",
        "\n",
        "        losses = dict(train=[], val=[], epoch_lens=[])\n",
        "\n",
        "        eras = EraController(stock_df=stock_df, fundamental_df=fundamental_df, meta_df=meta_df, macro_df=macro_df, conf=conf, **conf)\n",
        "        pbar = TqdmPostFix(eras, total=eras.total)\n",
        "        eras.register_pbar(pbar)\n",
        "\n",
        "        stopper = EarlyStop(conf.patience, conf.min_delta, model=(model if conf.checkpoint else None), pbar=pbar)\n",
        "\n",
        "        for i, (data_train, data_val) in enumerate(pbar):\n",
        "            \n",
        "            train_losses, val_losses = train_one_era(\n",
        "                run=run, \n",
        "                model=model, \n",
        "                optimizer=optimizer, \n",
        "                data_train=data_train,\n",
        "                data_val=data_val,\n",
        "                stopper=stopper.reset(),\n",
        "                losses=losses,\n",
        "                device=device, \n",
        "                conf=conf,\n",
        "                pbar=pbar,\n",
        "            )\n",
        "\n",
        "            metric_loss = calculate_metrics(eras, model, train_losses, val_losses, i, run, conf, pbar)\n",
        "\n",
        "            if conf.checkpoint and metric_loss < best_metric:\n",
        "                best_metric = metric_loss\n",
        "                best_wts = model.state_dict()\n",
        "\n",
        "        if conf.save_model:\n",
        "            if best_wts is not None:\n",
        "                model.load_state_dict(best_wts)\n",
        "            put_nn_model(model, run)\n",
        "\n",
        "    return model, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4rczchGmu__D"
      },
      "outputs": [],
      "source": [
        "def get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, params):\n",
        "    meta_cont_len = 1\n",
        "    meta_cat_len = np.array([len(meta_df[col].unique()) for col in meta_df.iloc[:,1:] if col != \"founding_year\"]) + 1\n",
        "    \n",
        "    stock_feats = 1\n",
        "    macro_feats = (macro_df.shape[1]-1)\n",
        "    funda_feats = (fundamental_df.loc[:,\"revenue\":].shape[1] - 1) + 2\n",
        "\n",
        "    n_features = stock_feats + macro_feats + funda_feats\n",
        "\n",
        "    if params.get(\"feature_subset\") is not None:\n",
        "        n_features = len(params[\"feature_subset\"])\n",
        "    \n",
        "    data_given_params = dict(\n",
        "        meta_cont_lens=(meta_cont_len, 1),\n",
        "        meta_cat_lens=list(map(lambda x: (x, int(math.ceil(x**0.25))), meta_cat_len)),\n",
        "        out_len=1 if params[\"forecast_problem\"] == Problem.volatility.name or params[\"train_loss\"] == \"ce_bankruptcy\" else params[\"forecast_w\"] if params[\"forecast_problem\"] == Problem.market_cap.name else funda_feats,\n",
        "        input_size=n_features,\n",
        "    )\n",
        "\n",
        "    return data_given_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5zbIHNQHUNH"
      },
      "source": [
        "# Run the loop! (Like Odd-Geir Lademo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(config):\n",
        "    assert pd.date_range(start=config[\"end_date\"], periods=config[\"forecast_w\"], freq=\"B\")[-1] < pd.to_datetime(\"2019-01-01\"), \"Training overlaps with test set\"\n",
        "    assert pd.date_range(end=config[\"start_date\"], periods=config[\"training_w\"], freq=\"B\")[0] >= pd.to_datetime(\"2000-01-01\"), \"Start time extends beyond Jan 2000\""
      ],
      "metadata": {
        "id": "RtXAX8FghjN6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_params = dict(\n",
        "    checkpoint=True,\n",
        "    feature_subset=None,\n",
        "    normalize_targets=None,\n",
        "    fundamental_targets=None,\n",
        ")"
      ],
      "metadata": {
        "id": "pfpzNFD2oEJ_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem = Problem.fundamentals"
      ],
      "metadata": {
        "id": "z1ViEd7QkUww"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wIKeTJNrln6X"
      },
      "outputs": [],
      "source": [
        "params_human = dict(\n",
        "    forecast_problem=problem.name,\n",
        "\n",
        "    cpus=1,\n",
        "    training_w=problem.training_w.h480,\n",
        "    forecast_w=problem.forecast_w.h240,\n",
        "    start_date=\"2001-12-31\",\n",
        "    end_date=\"2017-12-31\",\n",
        "    save_model=True,\n",
        "    batch_size=256,\n",
        "    use_pre_proc_data=True,\n",
        "    clamp=2,\n",
        "    dtype=\"float32\",\n",
        "\n",
        "    checkpoint=True,\n",
        "    feature_subset=None,\n",
        "\n",
        "    fundamental_targets=[8, 9, 10],\n",
        "    # normalize_targets=problem.normalize.mcap,\n",
        ")\n",
        "\n",
        "era_controller_params = dict(\n",
        "    sequential=dict(\n",
        "        mode=\"sequential\",\n",
        "        include_past=True,\n",
        "        queue_length=3,\n",
        "    ),\n",
        "    random=dict(\n",
        "        mode=\"random\",\n",
        "        sample_size=5,\n",
        "        distribution=[\"uniform\"][0],\n",
        "        max_samplings=200,\n",
        "    ),\n",
        ")[EraController.Mode.random]\n",
        "\n",
        "params_wb = dict(\n",
        "    max_epochs=1,\n",
        "    patience=1,\n",
        "    min_delta=0.0001,\n",
        "    learning_rate=0.0001,\n",
        "\n",
        "    hd=256,\n",
        "    dropout=0.25,\n",
        "    num_layers=5,\n",
        "    channels=256,\n",
        "    kernel_size=3,\n",
        "\n",
        "    meta_hd=16,\n",
        "\n",
        "    model=\"LstmV1\",\n",
        "    activation=\"leaky\",\n",
        "\n",
        "    train_loss=problem.loss.ce_bankruptcy,\n",
        "    val_loss=problem.loss.ce_bankruptcy,\n",
        ")\n",
        "\n",
        "params_from_data = get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, {**params_human, **params_wb})\n",
        "\n",
        "config = {\n",
        "    **default_params,\n",
        "    **params_human,\n",
        "    \"era_controller\": era_controller_params,\n",
        "    **params_wb,\n",
        "    **params_from_data,\n",
        "}\n",
        "\n",
        "validate(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3xYkJZgl_Vn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2b50bae7-4c5f-442a-a0ed-d078a6d8ad89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.18"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220610_090035-tlckv5rj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/krankile/master/runs/tlckv5rj\" target=\"_blank\">clean-terrain-1620</a></strong> to <a href=\"https://wandb.ai/krankile/master\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'checkpoint': True, 'feature_subset': None, 'normalize_targets': None, 'fundamental_targets': [8, 9, 10], 'forecast_problem': 'fundamentals', 'cpus': 1, 'training_w': 480, 'forecast_w': 240, 'start_date': '2001-12-31', 'end_date': '2017-12-31', 'save_model': True, 'batch_size': 256, 'use_pre_proc_data': True, 'clamp': 2, 'dtype': 'float32', 'era_controller': {'mode': 'random', 'sample_size': 5, 'distribution': 'uniform', 'max_samplings': 200}, 'max_epochs': 1, 'patience': 1, 'min_delta': 0.0001, 'learning_rate': 0.0001, 'hd': 256, 'dropout': 0.25, 'num_layers': 5, 'channels': 256, 'kernel_size': 3, 'meta_hd': 16, 'model': 'LstmV1', 'activation': 'leaky', 'train_loss': 'ce_bankruptcy', 'val_loss': 'ce_bankruptcy', 'meta_cont_lens': [1, 1], 'meta_cat_lens': [[110, 4], [6, 2], [91, 4], [285, 5], [3, 2], [5, 2], [7, 2], [14, 2], [58, 3]], 'out_len': 1, 'input_size': 37}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling before 2017-12-31 00:00:00 [9/200]:   4%|▎         | 7/200 [03:34<1:33:48, 29.16s/it, epoch=0, train_loss=1.07, val_loss=0.964, naive=1.28, triggers=0/1, best_loss=0.964, metric_loss=-.279]"
          ]
        }
      ],
      "source": [
        "# Run test of bankryptcy-prediction\n",
        "\n",
        "enablewb = True\n",
        "sweepid = None  # \"krankile/master/abkabs99\"\n",
        "\n",
        "if sweepid:\n",
        "    count = 500 # number of runs to execute\n",
        "    wb.agent(sweepid, partial(train,config=config, enablewb=enablewb), count=count)\n",
        "\n",
        "else:\n",
        "    model, losses = train(config=config, project=\"master\", entity=\"krankile\", enablewb=enablewb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-pezMbMjhSuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "training_loop.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}