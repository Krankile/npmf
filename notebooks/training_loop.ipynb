{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8F5tl4NL7FZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwo44VGZLhAo"
      },
      "source": [
        "## Kernel setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hKuFzk7aEmB9"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "91KPY7q0LUOw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb more_itertools\n",
        "!git clone https://github.com/Krankile/npmf.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUXnibj8YEi1",
        "outputId": "428bd4f0-e7d2-4e38-ce71-b98d469f0632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mankile\u001b[0m (\u001b[33mkrankile\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "# https://wandb.ai/authorize\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLAlA0htLgMY"
      },
      "source": [
        "## General setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1QSlgObXLq1p"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!cd npmf && git pull\n",
        "\n",
        "import math\n",
        "import multiprocessing\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import asdict, dataclass\n",
        "from datetime import datetime, timedelta\n",
        "from operator import itemgetter\n",
        "from typing import Callable, List, Tuple\n",
        "from functools import partial\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "from more_itertools import chunked\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from npmf.utils.colors import main, main2, main3\n",
        "from npmf.utils.dataset import TimeDeltaDataset, EraDataset, EraController\n",
        "from npmf.utils.dtypes import fundamental_types\n",
        "from npmf.utils.eikon import column_mapping\n",
        "from npmf.utils.tests.utils import pickle_df\n",
        "from npmf.utils.wandb import get_datasets, put_dataset, put_nn_model\n",
        "from npmf.utils.training import EarlyStop, to_device, TqdmPostFix, loss_fns\n",
        "from npmf.utils.models import models\n",
        "\n",
        "from numpy.ma.core import outerproduct\n",
        "from pandas.tseries.offsets import BDay, Day\n",
        "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "\n",
        "import wandb as wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hkTjKKLmLvpl"
      },
      "outputs": [],
      "source": [
        "np.seterr(all=\"raise\")\n",
        "\n",
        "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[main, main2, main3, \"black\"])\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)  # (6, 4) is default and used in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqy02oAvY7GM",
        "outputId": "4bc54b46-2a32-45e1-baa1-aa62741a057a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy50qmXr5_8V",
        "outputId": "1100af74-f096-4c14-a1cd-4ee17677dfc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  5 16:27:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    39W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YVFtfDk0pYtd"
      },
      "outputs": [],
      "source": [
        "pre_proc_data_dir = None\n",
        "np.random.seed(69)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGuFgO6jHPWX"
      },
      "source": [
        "\n",
        "# Get some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4GW-peR9fUqa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "reload_data = not True\n",
        "\n",
        "if reload_data or not \"stock_df\" in vars():\n",
        "    names = [\"stock-data:final\", \"fundamental-data:final\", \"meta-data:final\", \"macro-data:final\"]\n",
        "\n",
        "    stock_df, fundamental_df, meta_df, macro_df = get_datasets(names=names, project=\"master\")\n",
        "\n",
        "    stock_df = stock_df.drop(columns=[\"close_price\", \"currency\"]).astype({\"market_cap\": np.float32})\n",
        "    fundamental_df = fundamental_df.drop(columns=\"period_end_date\").astype(fundamental_types)\n",
        "    macro_df.iloc[:, 1:] = macro_df.iloc[:, 1:].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iZ7BM-BIDTZG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "reload_proc_data = True\n",
        "dont_load_proc_data = not True\n",
        "\n",
        "if (not dont_load_proc_data) and (reload_proc_data or not \"pre_proc_data_dir\" in vars() or pre_proc_data_dir is None):\n",
        "    with wb.init(job_type=\"get-data\", project=\"master\", entity=\"krankile\") as run:\n",
        "        art = run.use_artifact(\"era-datasets:240\")\n",
        "        pre_proc_data_dir = art.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txepzrB_QFNE"
      },
      "source": [
        "## Define a class to handle information across eras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PBGrBFNSYbWF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5zbIHNQHUNH"
      },
      "source": [
        "# Run the loop! (Like Odd-Geir Lademo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pZAHVCqKuIOb"
      },
      "outputs": [],
      "source": [
        "# Check if it's necessary to calculate naive loss every epoch\n",
        "def get_epoch_loss(model, optimizer, dataloader, loss_fn, device, run_type, conf):\n",
        "    model_losses = []\n",
        "    naive_losses = []\n",
        "    for data, meta_cont, meta_cat, target in to_device(dataloader, device):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred: torch.Tensor = model(torch.clamp(data, -conf.clamp, conf.clamp) if conf.clamp else data, meta_cont, meta_cat)\n",
        "\n",
        "        naive_loss = loss_fn(target.clone(), torch.ones(target.shape, device=device))\n",
        "        loss = loss_fn(target, y_pred)\n",
        "\n",
        "        model_losses.append(loss.item())\n",
        "        naive_losses.append(naive_loss.item())\n",
        "\n",
        "        if run_type == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model_losses, naive_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g3bvK3f9iHmo"
      },
      "outputs": [],
      "source": [
        "def eras_ahead_loss(model, data_loaders, optimizer, conf):\n",
        "    model_infront = []\n",
        "    naive_infront = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for loader in data_loaders:\n",
        "            model_loss, naive_loss = get_epoch_loss(model, optimizer, loader, loss_fns[\"mape_2\"], device, \"inference\", conf)\n",
        "        \n",
        "            model_infront += model_loss\n",
        "            naive_infront += naive_loss\n",
        "    \n",
        "    return np.array(model_infront), np.array(naive_infront)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lRHUgmiYTrC-"
      },
      "outputs": [],
      "source": [
        "def train_one_era(run, model, optimizer, data_train, data_val, stopper, losses, device, conf, pbar):\n",
        "\n",
        "    for epoch in range(conf.max_epochs):\n",
        "        epoch_losses = dict(train=[], val=[])\n",
        "        \n",
        "        pbar.update_postfix({\"epoch\": epoch})\n",
        "        for run_type, dataloader in {\"train\": data_train, \"val\": data_val}.items():\n",
        "            model.train(run_type == \"train\")\n",
        "            \n",
        "            epoch_model_loss, naive_losses = get_epoch_loss(model, optimizer, dataloader, loss_fns[conf[f\"{run_type}_loss\"]], device, run_type, conf)\n",
        "            epoch_losses[run_type] += epoch_model_loss\n",
        "\n",
        "            epoch_loss = np.mean(epoch_losses[run_type])\n",
        "            losses[run_type].append(epoch_loss)\n",
        "\n",
        "            run.log({f\"epoch_{run_type}\": epoch_loss, \"epoch\": epoch})\n",
        "\n",
        "        pbar.update_postfix({\"train_loss\": np.mean(epoch_losses[\"train\"]), \"val_loss\": np.mean(epoch_losses[\"val\"]), \"naive\": np.mean(naive_losses)})\n",
        "\n",
        "\n",
        "        # TODO: Implement checkpointing of the best model according to val_loss\n",
        "        if run_type == \"val\" and stopper(epoch_losses[\"val\"]):\n",
        "            losses[\"epoch_lens\"].append(epoch + 1)\n",
        "            break\n",
        "\n",
        "    return epoch_losses[\"train\"], epoch_losses[\"val\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sOlLqBTsMW1G"
      },
      "outputs": [],
      "source": [
        "def train(config, project=None, entity=None, enablewb=True) -> nn.Module:\n",
        "    \n",
        "    mode = \"online\" if enablewb else \"offline\"\n",
        "    with wb.init(config=config, project=project, entity=entity, job_type=\"training\", mode=mode) as run:\n",
        "\n",
        "        conf = run.config\n",
        "        print(conf)\n",
        "\n",
        "        model = models[conf.model](**conf).to(device)\n",
        "\n",
        "        # Try decreasing learning rate underway\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=conf.learning_rate)\n",
        "\n",
        "        losses = dict(train=[], val=[], epoch_lens=[])\n",
        "\n",
        "        eras = EraController(start_date=conf.start_date, end_metric_start_date=conf.end_date, queue_length=conf.queue_length, stock_df=stock_df, fundamental_df=fundamental_df, meta_df=meta_df, macro_df=macro_df, conf=conf)\n",
        "        pbar = TqdmPostFix(eras, total=eras.total)\n",
        "        stopper = EarlyStop(conf.patience, conf.min_delta, model=(model if conf.checkpoint else None), pbar=pbar)\n",
        "\n",
        "        for i, (data_train, data_val) in enumerate(pbar):\n",
        "            # Does this work??\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            pbar.set_description(f\"Era {eras.date} [{i+1}/{eras.total}]\")\n",
        "\n",
        "            train_losses, val_losses = train_one_era(\n",
        "                run=run, \n",
        "                model=model, \n",
        "                optimizer=optimizer, \n",
        "                data_train=data_train, \n",
        "                data_val=data_val,\n",
        "                stopper=stopper.reset(),\n",
        "                losses=losses,\n",
        "                device=device, \n",
        "                conf=conf,\n",
        "                pbar=pbar,\n",
        "            )\n",
        "\n",
        "            loaders_infront, loaders_end = eras.validation_loaders()\n",
        "            model_infront, naive_infront = eras_ahead_loss(model, loaders_infront, optimizer, conf)\n",
        "            model_end, naive_end = eras_ahead_loss(model, loaders_end, optimizer, conf)\n",
        "\n",
        "            metric_loss = 0.5*(np.mean(model_infront/naive_infront-1) +  np.mean(model_end/naive_end-1))\n",
        "\n",
        "            run.log({\"era_train\": np.mean(train_losses), \"era_val\" : np.mean(val_losses),\"model_infront\": np.mean(model_infront),\n",
        "                     \"naive_infront\": np.mean(naive_infront), \"model_end\": np.mean(model_end), \"naive_end\": np.mean(naive_end),\n",
        "                     \"metric_loss\": metric_loss, **eras.loader_to_na_dict[eras.date], \"time\": eras.date.timestamp(), \"era\": i})\n",
        "\n",
        "        if conf.save_model:\n",
        "            put_nn_model(model, run)\n",
        "\n",
        "    return model, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4rczchGmu__D"
      },
      "outputs": [],
      "source": [
        "def get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, params_human):\n",
        "    meta_cont_len = 1\n",
        "    meta_cat_len = np.array([len(meta_df[col].unique()) for col in meta_df.iloc[:,1:] if col != \"founding_year\"]) + 1\n",
        "    \n",
        "    stock_feats = 1\n",
        "    macro_feats = (macro_df.shape[1]-1)\n",
        "    funda_feats = (fundamental_df.loc[:,\"revenue\":].shape[1] - 1) + 2\n",
        "\n",
        "    n_features = stock_feats + macro_feats + funda_feats\n",
        "    \n",
        "    data_given_params = dict(\n",
        "        meta_cont_lens=(meta_cont_len, 1),\n",
        "        meta_cat_lens=list(map(lambda x: (x, int(math.ceil(x**0.25))), meta_cat_len)),\n",
        "        out_len=params_human[\"forecast_w\"],\n",
        "        input_size=n_features,\n",
        "    )\n",
        "    return data_given_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wIKeTJNrln6X"
      },
      "outputs": [],
      "source": [
        "params_human = dict(\n",
        "    cpus=1,\n",
        "    training_w=240,\n",
        "    forecast_w=240,\n",
        "    start_date=\"2000-12-31\",\n",
        "    end_date=\"2018-04-30\",\n",
        "    save_model=True,\n",
        "    batch_size=512,\n",
        "    pre_proc_data_dir=pre_proc_data_dir,\n",
        "    clamp=2,\n",
        "    dtype=\"float32\",\n",
        "    queue_length=6,\n",
        "\n",
        "    include_past=True,\n",
        "    checkpoint=True,\n",
        ")\n",
        "\n",
        "params_wb = dict(\n",
        "    max_epochs=500,\n",
        "    patience=10,\n",
        "    min_delta=0.0001,\n",
        "    learning_rate=0.0001,\n",
        "\n",
        "    hd=256,\n",
        "    dropout=0.1,\n",
        "    num_layers=5,\n",
        "    channels=256,\n",
        "    kernel_size=5,\n",
        "\n",
        "    meta_hd=16,\n",
        "\n",
        "    model=\"TcnV2\",\n",
        "    train_loss=\"mse_2\",\n",
        "    val_loss=\"mape_2\",\n",
        "    activation=\"relu\",\n",
        ")\n",
        "\n",
        "params_from_data = get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, params_human)\n",
        "\n",
        "config = {  \n",
        "    **params_human,\n",
        "    **params_wb,\n",
        "    **params_from_data,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "G3xYkJZgl_Vn",
        "outputId": "d6c98b26-140f-4a4f-be1a-5700cd28004e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220605_162942-4bqy3m0x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/krankile/master/runs/4bqy3m0x\" target=\"_blank\">atomic-oath-1019</a></strong> to <a href=\"https://wandb.ai/krankile/master\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cpus': 1, 'training_w': 240, 'forecast_w': 240, 'start_date': '2000-12-31', 'end_date': '2018-04-30', 'save_model': True, 'batch_size': 512, 'pre_proc_data_dir': './artifacts/era-datasets:v4', 'clamp': 2, 'dtype': 'float32', 'queue_length': 6, 'include_past': True, 'checkpoint': True, 'max_epochs': 500, 'patience': 10, 'min_delta': 0.0001, 'learning_rate': 0.001, 'hd': 256, 'dropout': 0.1, 'num_layers': 5, 'channels': 256, 'kernel_size': 5, 'meta_hd': 16, 'model': 'TcnV2', 'train_loss': 'mse_2', 'val_loss': 'mape_2', 'activation': 'relu', 'meta_cont_lens': [1, 1], 'meta_cat_lens': [[110, 4], [6, 2], [91, 4], [285, 5], [3, 2], [5, 2], [7, 2], [14, 2], [58, 3]], 'out_len': 240, 'input_size': 37}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Era 2001-08-31 00:00:00 [9/209]:   4%|▍         | 8/209 [07:06<3:03:07, 54.66s/it, epoch=10, train_loss=0.0972, val_loss=0.244, naive=0.229, triggers=10/10, best_loss=0.229]"
          ]
        }
      ],
      "source": [
        "# 05.06.2022 Test checkpointing and new pbar handling\n",
        "# Also, long forecast horizon and with past data as well\n",
        "\n",
        "enablewb = True\n",
        "sweepid = None  #\"krankile/master/q8hau0w8\"\n",
        "\n",
        "if sweepid:\n",
        "    count = 500 # number of runs to execute\n",
        "    wb.agent(sweepid, partial(train,config=config, enablewb=enablewb), count=count)\n",
        "\n",
        "else:\n",
        "    model, losses = train(config=config, project=\"master\", entity=\"krankile\", enablewb=enablewb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh0Br_DiWixV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "training_loop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}