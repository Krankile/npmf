{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7868a6",
      "metadata": {
        "id": "3e7868a6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4198ca",
      "metadata": {
        "id": "9e4198ca"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install eikon\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b056c9a0",
      "metadata": {
        "id": "b056c9a0"
      },
      "outputs": [],
      "source": [
        "import eikon as ek\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1e83d4",
      "metadata": {
        "id": "bd1e83d4"
      },
      "outputs": [],
      "source": [
        "#\"api_key_lk\"\n",
        "ek.set_app_key(\"example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32835af0",
      "metadata": {
        "id": "32835af0"
      },
      "source": [
        "## Screen companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944ef578",
      "metadata": {
        "id": "944ef578"
      },
      "outputs": [],
      "source": [
        "mic_exchanges = pd.read_csv(\"mic_codes.csv\").set_index(\"MIC\") #Can be used to look up specific stock exchanges codes :) (Y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf666227",
      "metadata": {
        "id": "bf666227"
      },
      "outputs": [],
      "source": [
        "oil_osebx_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.ExchangeMarketIdCode,\"XOSL\"), IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
        "fields_oil_osebx_screen = [\"TR.CommonName\"]#[\"TR.CommonName\",\"TR.CompanyMarketCap\",\"TR.ExchangeName\",\"TR.TRBCBusinessSector\",\"TR.TotalReturn3Mo\"]\n",
        "\n",
        "osbx_companies, e = ek.get_data(oil_osebx_screen, fields_oil_osebx_screen)\n",
        "osbx_companies = osbx_companies.set_index(\"Instrument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091dd0cf",
      "metadata": {
        "id": "091dd0cf"
      },
      "outputs": [],
      "source": [
        "oil_global_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
        "fields_oil_global_screen = [\"TR.CommonName\"]\n",
        "\n",
        "global_oil, e = ek.get_data(oil_global_screen, fields_oil_global_screen)\n",
        "global_oil = global_oil.set_index(\"Instrument\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ae7040",
      "metadata": {
        "id": "c0ae7040"
      },
      "source": [
        "Now we have dataframe of all noted oil companies (with mcap > USD 5m) in eikon refinitives entire database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c52216",
      "metadata": {
        "id": "99c52216"
      },
      "source": [
        "# Collect data from eikon refinitiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c932faf0",
      "metadata": {
        "id": "c932faf0"
      },
      "outputs": [],
      "source": [
        "######## INPUTS ########\n",
        "lst_of_tickers = global_oil.index.to_list()\n",
        "\n",
        "#Eikon parameters\n",
        "start_date = '2000-01-01'\n",
        "end_date = '2022-04-21'\n",
        "ek_params = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ', \"Curn\":\"USD\"}\n",
        "\n",
        "#Max http company request at once\n",
        "search_limit = 10_000\n",
        "\n",
        "#What data to get\n",
        "get_stock_data = False\n",
        "get_meta_data = True\n",
        "get_fundamental_data = False \n",
        "get_broker_data = False\n",
        "\n",
        "toggle_dict = {'stock_data':get_stock_data, 'meta_data':get_meta_data,\n",
        "               'fundamental_data':get_fundamental_data, 'broker_data':get_broker_data}\n",
        "\n",
        "\n",
        "\n",
        "params = ek_params | toggle_dict | {'limit': search_limit} \n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926ea32f",
      "metadata": {
        "id": "926ea32f"
      },
      "source": [
        "## We define functions to find stock, meta, fundamental and broker estimates data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bcfae46",
      "metadata": {
        "id": "5bcfae46"
      },
      "outputs": [],
      "source": [
        "def _sub_lists(data, size_m):\n",
        "    return [data[x:x+size_m] for x in range(0, len(data), size_m)]\n",
        "\n",
        "#Function to counteract http timeout\n",
        "def _divide_pull_request(lst_of_tickers, fields, params, suffix):\n",
        "\n",
        "    p = {key: val for key, val in params.items() if key in ek_params}    \n",
        "    if len(lst_of_tickers) > params['limit']:\n",
        "        dfs = []\n",
        "        for sub_ticker_lst in tqdm(_sub_lists(lst_of_tickers, params['limit']), suffix):\n",
        "            df_sub, err = ek.get_data(lst_of_tickers, fields, p)\n",
        "            print(df_sub)\n",
        "            dfs.append(df_sub)\n",
        "        df = pd.concat(dfs, axis=0)\n",
        "    else: \n",
        "        df, err = ek.get_data(lst_of_tickers, fields, p)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c59700e",
      "metadata": {
        "id": "1c59700e"
      },
      "outputs": [],
      "source": [
        "def stock_data(lst_of_tickers, params):\n",
        "    \n",
        "    params_new = params.copy()\n",
        "    params_new['Frq'] = 'D'\n",
        "    \n",
        "    fields = ['TR.CompanyMarketCap.Date','TR.CompanyMarketCap', 'TR.PriceClose',\n",
        "              'TR.CompanyMarketCap.Currency'] #TR.F.ComShrOutsTot\n",
        "    \n",
        "    stock_df = _divide_pull_request(lst_of_tickers, fields=fields, params=params_new, suffix=' Getting time series')\n",
        "    \n",
        "    return stock_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41389f68",
      "metadata": {
        "id": "41389f68"
      },
      "outputs": [],
      "source": [
        "#Meta data collector\n",
        "def meta_data(lst_of_tickers):\n",
        "    geography = ['TR.ExchangeMarketIdCode', 'TR.HeadquartersRegionAlt', 'TR.HeadquartersCountry', 'TR.HQStateProvince']\n",
        "    sectors = ['TR.TRBCEconomicSector', 'TR.TRBCBusinessSector', 'TR.TRBCIndustryGroup', 'TR.TRBCIndustry', 'TR.TRBCActivity']\n",
        "    founded = ['TR.OrgFoundedYear']\n",
        "\n",
        "    meta_data = geography + founded + sectors  \n",
        "    meta_df, _ = ek.get_data(lst_of_tickers, meta_data)\n",
        "    meta_df = meta_df.set_index(\"Instrument\")\n",
        "    \n",
        "    meta_df['Organization Founded Year'] = meta_df['Organization Founded Year'].replace(0, np.NaN) #<-- Eikon hilariously uses 0 instead of Na for missing year value\n",
        "    \n",
        "    \n",
        "    return meta_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c6d708",
      "metadata": {
        "id": "48c6d708"
      },
      "outputs": [],
      "source": [
        "#Fundamental data collector\n",
        "\n",
        "def fundamental_data(lst_of_tickers, params):\n",
        "    #fields    \n",
        "    profits = ['TR.TotalRevenue', 'TR.GrossProfit','TR.EBITDA','TR.EBIT', 'TR.F.NetIncAfterTax']#, 'TR.EV','MKT_CAP']\n",
        "    balance = ['TR.F.TotAssets','TR.F.TotCurrAssets','TR.F.TotLiab','TR.F.TotCurrLiab','TR.F.LTDebtPctofTotAssets','TR.F.STDebtPctofTotAssets']#TR.F.TotLiab(Period=FY0)\n",
        "    cash_flow = ['TR.F.LeveredFOCF']\n",
        "    fundamental_data = profits + balance + cash_flow \n",
        "    \n",
        "    other = []#['TR.InsiderBuyDepthComp'] <--- NA only, could be interesting to use....   \n",
        "    reported_dates = ['TR.TotalRevenue.date','TR.TotalRevenue.periodenddate','TR.BSOriginalAnnouncementDate']\n",
        "    \n",
        "    fields = reported_dates + fundamental_data + other\n",
        "    \n",
        "    #collect data\n",
        "    fundamental_df = _divide_pull_request(lst_of_tickers, fields, params, suffix=' Getting fundamentals')\n",
        "    \n",
        "    return fundamental_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8adc04",
      "metadata": {
        "id": "1a8adc04"
      },
      "outputs": [],
      "source": [
        "def broker_estimates(lst_of_tickers, params):\n",
        "    \n",
        "    params_new = params.copy()\n",
        "    params_new[\"Period\"] = \"FY1\"    \n",
        "    \n",
        "    fields = [\"TR.EPSMean\",\"TR.EPSMean.periodenddate\",\"TR.EBITMean\",'TR.RevenueMean',\n",
        "              \"TR.ROAMean\",\"TR.ROEMean\",\"TR.FCFMean\",\"TR.TotalAssets\",\"TR.MeanPctChg(Period=FY1,WP=60d)\"]\n",
        "    \n",
        "    estimates_df, err = ek.get_data(lst_of_tickers, fields, params)\n",
        "    return estimates_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21edab25",
      "metadata": {
        "id": "21edab25"
      },
      "outputs": [],
      "source": [
        "def get_data(lst_of_tickers, params):\n",
        "    \n",
        "    stock_df = None\n",
        "    meta_df = None\n",
        "    fundamental_df = None\n",
        "    broker_df = None\n",
        "    \n",
        "    if params['stock_data']: \n",
        "        stock_df = stock_data(lst_of_tickers, params)\n",
        "\n",
        "    if params['meta_data']:\n",
        "        meta_df = meta_data(lst_of_tickers)\n",
        "\n",
        "    if params['fundamental_data']:\n",
        "        fundamental_df = fundamental_data(lst_of_tickers, params)\n",
        "\n",
        "    if params['broker_data']:\n",
        "        broker_df = broker_estiqates(lst_of_tickers, params)\n",
        "    \n",
        "    return stock_df, meta_df, fundamental_df, broker_df\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5659be0b",
      "metadata": {
        "id": "5659be0b"
      },
      "outputs": [],
      "source": [
        "def save_data(file_name, save_per_n_http_request, lst_of_tickers, params):\n",
        "    \n",
        "    non_collected_tickers = []\n",
        "\n",
        "    name_to_index = {}\n",
        "    dfs = {}\n",
        "    for i, possible_key in enumerate([\"stock_data\", \"meta_data\", \"fundamental_data\", \"broker_data\"]):\n",
        "        if params[possible_key]:\n",
        "            name_to_index[possible_key] = i\n",
        "            dfs[possible_key] = []\n",
        "    \n",
        "    partioned_lst_of_tickers = _sub_lists(lst_of_tickers, params[\"limit\"])        \n",
        "    for i, sub_ticker_lst in enumerate(tqdm(partioned_lst_of_tickers, \"saving loop\")):    \n",
        "        \n",
        "        try:\n",
        "            raw_data_dfs = get_data(sub_ticker_lst, params)\n",
        "            \n",
        "            for key in name_to_index:\n",
        "           \n",
        "                dfs[key] = dfs[key] + [raw_data_dfs[name_to_index[key]]]\n",
        "                \n",
        "                \n",
        "                \n",
        "            if not (i % save_per_n_http_request):\n",
        "                for key in name_to_index:\n",
        "                    df = pd.concat(dfs[key], axis=0)\n",
        "                    df = df.reset_index()\n",
        "                    \n",
        "                    df.to_feather(f\"{file_name}_save={i}_type={key}.feather\")\n",
        "                    \n",
        "                    \n",
        "                    dfs[key] = []\n",
        "\n",
        "        except ek.EikonError as err:\n",
        "            for key in name_to_index:\n",
        "                dfs[key] = []\n",
        "                \n",
        "            non_collected_tickers += sub_ticker_lst\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            for key in name_to_index:\n",
        "                dfs[key] = []\n",
        "                \n",
        "            non_collected_tickers += sub_ticker_lst\n",
        "            \n",
        "    #Write crashes to file       \n",
        "    with open(f\"{file_name}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(non_collected_tickers))\n",
        "    \n",
        "    #Save last data if there are rests\n",
        "    for key in name_to_index:\n",
        "            break\n",
        "            if dfs[key] != []:\n",
        "                df = pd.concat(dfs[key], axis=0)\n",
        "\n",
        "                df = df.reset_index()\n",
        "\n",
        "                #wtfffff\n",
        "                df.to_feather(f\"{file_name}_save={len(partioned_lst_of_tickers)}_type={key}.feather\")\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be13dc1a",
      "metadata": {
        "id": "be13dc1a"
      },
      "outputs": [],
      "source": [
        "save_toggle = False\n",
        "\n",
        "file_name = \"C:/Users/kjartkra/Untitled Folder/meta_data/global_oil\"\n",
        "if save_toggle: \n",
        "    save_data(file_name, 1, lst_of_tickers, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a572207",
      "metadata": {
        "scrolled": true,
        "id": "0a572207"
      },
      "outputs": [],
      "source": [
        "def _time_interval(start_date, end_date):\n",
        "    y0 = int(start_date.split(\"-\")[0])\n",
        "    yn = int(end_date.split(\"-\")[0])\n",
        "    in_between_dates = [f\"{str(year)}-01-01\" for year in range(y0+1,yn,7)]\n",
        "    return [start_date] + in_between_dates  + [end_date]\n",
        "    \n",
        "        \n",
        "\n",
        "def macro_data(lst_of_tickers, ek_get_timeseries_fields, params):\n",
        "        start_and_ends = _time_interval(params[\"SDate\"],params[\"EDate\"])\n",
        "        \n",
        "        tickers_to_serie = {}\n",
        "        for ticker in lst_of_tickers:\n",
        "            tickers_to_serie[ticker] = []\n",
        "            for i in range(len(start_and_ends)-1):\n",
        "                try: \n",
        "                    time_series = ek.get_timeseries(ticker, fields=ek_get_timeseries_fields,\n",
        "                                                    start_date=start_and_ends[i], end_date=start_and_ends[i+1], interval=params[\"interval\"])\n",
        "                                 \n",
        "                except ek.EikonError as err:\n",
        "                    if err.code ==-1:\n",
        "                        time_series = ek.get_timeseries(\"BRT-\", fields=ek_get_timeseries_fields, start_date=start_and_ends[i], end_date=start_and_ends[i+1],interval=params[\"interval\"])\n",
        "                        time_series[ek_get_timeseries_fields] = np.nan\n",
        "                        \n",
        "                    if err.code ==  2504:\n",
        "                        print(\"backend error\")\n",
        "                        time.sleep(2)\n",
        "                        time_series = ek.get_timeseries(ticker, fields=ek_get_timeseries_fields,\n",
        "                                                    start_date=start_and_ends[i], end_date=start_and_ends[i+1], interval=params[\"interval\"])\n",
        "                        \n",
        "                tickers_to_serie[ticker] = tickers_to_serie[ticker] + [time_series]\n",
        "            \n",
        "            tickers_to_serie[ticker] = pd.concat(tickers_to_serie[ticker], axis=0)\n",
        "            \n",
        "        return tickers_to_serie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395f2100",
      "metadata": {
        "id": "395f2100"
      },
      "outputs": [],
      "source": [
        "def dict_to_df(dictionary):\n",
        "    dates = set()\n",
        "\n",
        "    for key, frame in dictionary.items():\n",
        "        dates |= set(frame.index.values)\n",
        "    \n",
        "    index = pd.Index(list(sorted(dates)))\n",
        "    \n",
        "    all_macro = pd.DataFrame(index=index)\n",
        "\n",
        "    for key, frame in dictionary.items():\n",
        "        frame = frame[~frame.index.duplicated(keep='first')]\n",
        "        all_macro[key] = frame\n",
        "\n",
        "    return all_macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b470ecf8",
      "metadata": {
        "id": "b470ecf8"
      },
      "outputs": [],
      "source": [
        "def folder_to_df(folder_with_data):\n",
        "    files = glob.glob(folder_with_data + '/*.feather')\n",
        "    dfs = []\n",
        "    for file in files:\n",
        "        dfs.append(pd.read_feather(file).set_index(\"index\"))\n",
        "\n",
        "    df_big = pd.concat(dfs, axis=0).reset_index()\n",
        "    df_big = df_big.drop(\"index\", axis=1)\n",
        "    return df_big"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81226e40",
      "metadata": {
        "id": "81226e40"
      },
      "outputs": [],
      "source": [
        "def upload_artifact(run, dataframe_file_location, artifact_name):\n",
        "    \n",
        "    artifact = wandb.Artifact(artifact_name, type='dataset')\n",
        "\n",
        "    # Add a file to the artifact's contents\n",
        "    artifact.add_file(dataframe_file_location)\n",
        "\n",
        "    # Save the artifact version to W&B and mark it as the output of this run\n",
        "    run.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9fa47f",
      "metadata": {
        "id": "eb9fa47f"
      },
      "outputs": [],
      "source": [
        "collect_meta_data = False\n",
        "if collect_meta_data:\n",
        "    stock_df, meta_df, fundamental_df, broker_df = get_data(lst_of_tickers, params)\n",
        "\n",
        "    meta_location = 'C:/Users/kjartkra/Untitled Folder/meta_oil.feather'\n",
        "    meta_df.reset_index().to_feather(meta_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b491de",
      "metadata": {
        "id": "d7b491de"
      },
      "outputs": [],
      "source": [
        "collect_macro_data = False\n",
        "\n",
        "if collect_macro_data:\n",
        "    macro_oil_params = ek_params.copy()\n",
        "    macro_oil_params[\"interval\"] = \"daily\"\n",
        "    macro_oil_series = [\"BRT-\", \"CLc1\", \"WTCLc1\", \"LNG-AS\", \".VIX\",'EUR=', 'GBP=', \"CNY=\", ]\n",
        "    macro_oil_fields = [\"CLOSE\"]\n",
        "\n",
        "    macro_oil = macro_data(macro_oil_series, macro_oil_fields , macro_oil_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a623268e",
      "metadata": {
        "id": "a623268e"
      },
      "outputs": [],
      "source": [
        "fundamentals_df = folder_to_df('C:/Users/kjartkra/Untitled Folder/fundamental_data')\n",
        "fundamentals_location = 'C:/Users/kjartkra/Untitled Folder/fundamentals_oil.feather'\n",
        "\n",
        "fundamentals_df.to_feather(fundamentals_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97472cfd",
      "metadata": {
        "id": "97472cfd"
      },
      "outputs": [],
      "source": [
        "macro_df = dict_to_df(macro_oil).reset_index()\n",
        "oil_company_df = folder_to_df(\"C:/Users/kjartkra/Untitled Folder/stock_data/)\n",
        "\n",
        "macro_location = 'C:/Users/kjartkra/Untitled Folder/macro_oil.feather'\n",
        "company_location = 'C:/Users/kjartkra/Untitled Folder/companies_oil.feather'\n",
        "\n",
        "macro_df.to_feather(macro_location)\n",
        "oil_company_df.to_feather(company_location)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e04c0eb",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "0e04c0eb",
        "outputId": "97c074a1-bbad-4d21-cb69-3ee070a5f2cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\kjartkra\\Untitled Folder\\wandb\\run-20220426_132936-8ydhaig0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/krankile/master-test/runs/8ydhaig0\" target=\"_blank\">gentle-shadow-17</a></strong> to <a href=\"https://wandb.ai/krankile/master-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.372 MB of 0.372 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gentle-shadow-17</strong>: <a href=\"https://wandb.ai/krankile/master-test/runs/8ydhaig0\" target=\"_blank\">https://wandb.ai/krankile/master-test/runs/8ydhaig0</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20220426_132936-8ydhaig0\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "upload_stocks = False\n",
        "upload_meta = True\n",
        "upload_fundamentals = False\n",
        "upload_macro = False\n",
        "\n",
        "\n",
        "if  upload_stocks or upload_meta or upload_fundamentals or upload_macro:\n",
        "    with wandb.init(project=\"master-test\") as run:\n",
        "        if upload_stocks:\n",
        "            upload_artifact(run, company_location, \"oil-company-data\")\n",
        "        if upload_meta: \n",
        "            upload_artifact(run, meta_location, \"oil-meta-data\")\n",
        "        if upload_fundamentals:\n",
        "            upload_artifact(run, fundamentals_location, \"oil-fundamental-data\")\n",
        "        if upload_macro:\n",
        "            upload_artifact(run, macro_location, \"oil-macro-data\")\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec825654",
      "metadata": {
        "id": "ec825654"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb0ab86",
      "metadata": {
        "id": "ecb0ab86"
      },
      "outputs": [],
      "source": [
        "df_big"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e5f326",
      "metadata": {
        "id": "a9e5f326"
      },
      "outputs": [],
      "source": [
        "wandb.init()\n",
        "\n",
        "artifact = wandb.Artifact('mnist', type='dataset')\n",
        "artifact.add_dir('mnist/')\n",
        "wandb.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b7dbf9",
      "metadata": {
        "id": "56b7dbf9"
      },
      "outputs": [],
      "source": [
        "time_series_df_2, meta_df, fundamental_df, broker_df = get_data(lst_of_tickers[:5], params)\n",
        "time_series_df_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b50e0e",
      "metadata": {
        "id": "66b50e0e"
      },
      "outputs": [],
      "source": [
        "time_series_df_2[\"Number Of Stocks\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4657359",
      "metadata": {
        "id": "a4657359"
      },
      "outputs": [],
      "source": [
        "time_series_df[\"Common Shares - Outstanding - Total\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab00243",
      "metadata": {
        "id": "5ab00243"
      },
      "outputs": [],
      "source": [
        "time_series_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5d3c81",
      "metadata": {
        "id": "5a5d3c81"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "time_series_df.to_excel(\"stock_data_2.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69540527",
      "metadata": {
        "id": "69540527"
      },
      "outputs": [],
      "source": [
        "#Conclusion, makes small difference in time to process at server\n",
        "test_time = False\n",
        "\n",
        "if test_time: \n",
        "    params_single = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ','Period': 'FQ0'}\n",
        "    params_curn = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ','Period': 'FQ0', \"Curn\":\"USD\"}\n",
        "    \n",
        "    \n",
        "    start_time = time.time()\n",
        "    data,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params_single)\n",
        "    print(\"--- simple: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    data_usd,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params_curn)\n",
        "    print(\"--- Curn: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    data_all,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params)\n",
        "    print(\"--- Scale & Curn: %s seconds ---\" % (time.time() - start_time))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "data_collection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ec825654"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}