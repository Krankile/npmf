{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7868a6",
      "metadata": {
        "id": "3e7868a6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4198ca",
      "metadata": {
        "id": "9e4198ca"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install eikon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b056c9a0",
      "metadata": {
        "id": "b056c9a0"
      },
      "outputs": [],
      "source": [
        "import eikon as ek\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1e83d4",
      "metadata": {
        "id": "bd1e83d4"
      },
      "outputs": [],
      "source": [
        "#\"api_key_lk\"\n",
        "#ek.set_app_key(\"EXAMPLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32835af0",
      "metadata": {
        "id": "32835af0"
      },
      "source": [
        "## Screen companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944ef578",
      "metadata": {
        "id": "944ef578"
      },
      "outputs": [],
      "source": [
        "mic_exchanges = pd.read_csv(\"mic_codes.csv\").set_index(\"MIC\") #Can be used to look up specific stock exchanges codes :) (Y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf666227",
      "metadata": {
        "id": "bf666227"
      },
      "outputs": [],
      "source": [
        "oil_osebx_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.ExchangeMarketIdCode,\"XOSL\"), IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
        "fields_oil_osebx_screen = [\"TR.CommonName\"]#[\"TR.CommonName\",\"TR.CompanyMarketCap\",\"TR.ExchangeName\",\"TR.TRBCBusinessSector\",\"TR.TotalReturn3Mo\"]\n",
        "\n",
        "osbx_companies, e = ek.get_data(oil_osebx_screen, fields_oil_osebx_screen)\n",
        "osbx_companies = osbx_companies.set_index(\"Instrument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091dd0cf",
      "metadata": {
        "id": "091dd0cf"
      },
      "outputs": [],
      "source": [
        "oil_global_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
        "fields_oil_global_screen = [\"TR.CommonName\"]\n",
        "\n",
        "global_oil, e = ek.get_data(oil_global_screen, fields_oil_global_screen)\n",
        "global_oil = global_oil.set_index(\"Instrument\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ae7040",
      "metadata": {
        "id": "c0ae7040"
      },
      "source": [
        "Now we have dataframe of all noted companies (with mcap > USD 5m) in eikon refinitives entire database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c52216",
      "metadata": {
        "id": "99c52216"
      },
      "source": [
        "# Collect data from eikon refinitiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c932faf0",
      "metadata": {
        "id": "c932faf0"
      },
      "outputs": [],
      "source": [
        "######## inputs ########\n",
        "lst_of_tickers = global_oil.index.to_list()\n",
        "\n",
        "#Eikon parameters\n",
        "start_date = '2000-01-01'\n",
        "end_date = '2022-04-21'\n",
        "ek_params = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ', \"Curn\":\"USD\"}\n",
        "\n",
        "#Max http company request at once\n",
        "search_limit = 1\n",
        "\n",
        "#What data to get\n",
        "get_stock_data = True\n",
        "get_meta_data = False\n",
        "get_fundamental_data = False \n",
        "get_broker_data = False\n",
        "\n",
        "toggle_dict = {'stock_data':get_stock_data, 'meta_data':get_meta_data,\n",
        "               'fundamental_data':get_fundamental_data, 'broker_data':get_broker_data}\n",
        "\n",
        "\n",
        "\n",
        "params = ek_params | toggle_dict | {'limit': search_limit} \n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926ea32f",
      "metadata": {
        "id": "926ea32f"
      },
      "source": [
        "## We define functions to find stock, meta, fundamental and broker estimates data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c59700e",
      "metadata": {
        "id": "1c59700e"
      },
      "outputs": [],
      "source": [
        "def _sub_lists(data, size_m):\n",
        "    return [data[x:x+size_m] for x in range(0, len(data), size_m)]\n",
        "\n",
        "#Function to counteract http timeout\n",
        "def _divide_pull_request(lst_of_tickers, fields, params, suffix):\n",
        "    p = {key: val for key, val in params.items() if key in ek_params}\n",
        "    if len(lst_of_tickers) > params['limit']:\n",
        "        dfs = []\n",
        "        for sub_ticker_lst in tqdm(_sub_lists(lst_of_tickers, params['limit']), suffix):\n",
        "            df_sub, err = ek.get_data(lst_of_tickers, fields, p)\n",
        "            dfs.append(df_sub)\n",
        "        df = pd.concat(dfs, axis=0)\n",
        "    else: \n",
        "     \n",
        "        df, err = ek.get_data(lst_of_tickers, fields, p)\n",
        "    return df\n",
        "\n",
        "def stock_data(lst_of_tickers, params):\n",
        "    \n",
        "    params_new = params.copy()\n",
        "    params_new['Frq'] = 'D'\n",
        "    \n",
        "    fields = ['TR.CompanyMarketCap.Date','TR.CompanyMarketCap', 'TR.PriceClose',\n",
        "              'TR.CompanyMarketCap.Currency'] #TR.F.ComShrOutsTot\n",
        "    \n",
        "    stock_df = _divide_pull_request(lst_of_tickers, fields=fields, params=params_new, suffix=' Getting time series')\n",
        "    \n",
        "    return stock_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41389f68",
      "metadata": {
        "id": "41389f68"
      },
      "outputs": [],
      "source": [
        "#Meta data collector\n",
        "def meta_data(lst_of_tickers):\n",
        "    geography = ['TR.ExchangeMarketIdCode', 'TR.HeadquartersRegionAlt', 'TR.HeadquartersCountry', 'TR.HQStateProvince']\n",
        "    sectors = ['TR.TRBCEconomicSector', 'TR.TRBCBusinessSector', 'TR.TRBCIndustryGroup', 'TR.TRBCIndustry', 'TR.TRBCActivity']\n",
        "    founded = ['TR.OrgFoundedYear']\n",
        "\n",
        "    meta_data = geography + founded + sectors  \n",
        "    meta_df, _ = ek.get_data(lst_of_tickers, meta_data)\n",
        "    meta_df = meta_df.set_index(\"Instrument\")\n",
        "    \n",
        "    meta_df['Organization Founded Year'] = meta_df['Organization Founded Year'].replace(0, np.NaN) #<-- Eikon hilariously uses 0 instead of Na for missing year value\n",
        "    \n",
        "    \n",
        "    return meta_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c6d708",
      "metadata": {
        "id": "48c6d708"
      },
      "outputs": [],
      "source": [
        "#Fundamental data collector\n",
        "\n",
        "def fundamental_data(lst_of_tickers, params):\n",
        "    \n",
        "    #fields    \n",
        "    profits = ['TR.TotalRevenue', 'TR.GrossProfit','TR.EBITDA','TR.EBIT', 'TR.F.NetIncAfterTax']#, 'TR.EV','MKT_CAP']\n",
        "    balance = ['TR.F.TotAssets','TR.F.TotCurrAssets','TR.F.TotLiab','TR.F.TotCurrLiab','TR.F.LTDebtPctofTotAssets','TR.F.STDebtPctofTotAssets']#TR.F.TotLiab(Period=FY0)\n",
        "    cash_flow = ['TR.F.LeveredFOCF']\n",
        "    fundamental_data = profits + balance + cash_flow \n",
        "    \n",
        "    other = []#['TR.InsiderBuyDepthComp'] <--- NA only, could be interesting to use....   \n",
        "    reported_dates = ['TR.TotalRevenue.date','TR.TotalRevenue.periodenddate','TR.BSOriginalAnnouncementDate']\n",
        "    \n",
        "    fields = fundamental_data + other + reported_dates\n",
        "    \n",
        "    #collect data\n",
        "    fundamental_df = _divide_pull_request(lst_of_tickers, params['limit'], fields, params, suffix=' Getting fundamentals')\n",
        "    \n",
        "    return fundamental_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8adc04",
      "metadata": {
        "id": "1a8adc04"
      },
      "outputs": [],
      "source": [
        "def broker_estimates(lst_of_tickers, params):\n",
        "    \n",
        "    params_new = params.copy()\n",
        "    params_new[\"Period\"] = \"FY1\"    \n",
        "    \n",
        "    fields = [\"TR.EPSMean\",\"TR.EPSMean.periodenddate\",\"TR.EBITMean\",'TR.RevenueMean',\n",
        "              \"TR.ROAMean\",\"TR.ROEMean\",\"TR.FCFMean\",\"TR.TotalAssets\",\"TR.MeanPctChg(Period=FY1,WP=60d)\"]\n",
        "    \n",
        "    estimates_df, err = ek.get_data(lst_of_tickers, fields, params)\n",
        "    return estimates_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21edab25",
      "metadata": {
        "id": "21edab25"
      },
      "outputs": [],
      "source": [
        "def get_data(lst_of_tickers, params):\n",
        "    \n",
        "    time_series_df = None\n",
        "    meta_df = None\n",
        "    fundamental_df = None\n",
        "    broker_df = None\n",
        "    \n",
        "    if params['stock_data']: \n",
        "        stock_df = stock_data(lst_of_tickers, params)\n",
        "\n",
        "    if params['meta_data']:\n",
        "        meta_df = meta_data(lst_of_tickers)\n",
        "\n",
        "    if params['fundamental_data']:\n",
        "        fundamental_df = fundamental_data(lst_of_tickers, params)\n",
        "\n",
        "    if params['broker_data']:\n",
        "        broker_df = broker_estiqates(lst_of_tickers, params)\n",
        "    \n",
        "    return stock_df, meta_df, fundamental_df, broker_df\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5659be0b",
      "metadata": {
        "id": "5659be0b"
      },
      "outputs": [],
      "source": [
        "def save_data(file_name, save_per_n_http_request, lst_of_tickers, params):\n",
        "    \n",
        "    non_collected_tickers = []\n",
        "\n",
        "\n",
        "    name_to_index = {}\n",
        "    dfs = {}\n",
        "    for i, possible_key in enumerate([\"stock_data\", \"meta_data\", \"fundamental_data\", \"broker_data\"]):\n",
        "        if params[possible_key]:\n",
        "            name_to_index[possible_key] = i\n",
        "            dfs[possible_key] = []\n",
        "    \n",
        "    partioned_lst_of_tickers = _sub_lists(lst_of_tickers, params[\"limit\"])        \n",
        "    for i, sub_ticker_lst in enumerate(tqdm(partioned_lst_of_tickers, \"saving loop\")):    \n",
        "        try:\n",
        "            raw_data_dfs = get_data(sub_ticker_lst, params)\n",
        "\n",
        "            for key in name_to_index:\n",
        "           \n",
        "                dfs[key] = dfs[key] + [raw_data_dfs[name_to_index[key]]]\n",
        "                \n",
        "                \n",
        "                \n",
        "            if (not (i % save_per_n_http_request)) and i != 0:\n",
        "                for key in name_to_index:\n",
        "                    df = pd.concat(dfs[key], axis=0)\n",
        "                    df = df.reset_index()\n",
        "\n",
        "                    #wtfffff\n",
        "                    df.to_feather(f\"{file_name}_save={i}_type={key}.feather\")\n",
        "                    dfs[key] = []\n",
        "\n",
        "        except: \n",
        "            non_collected_tickers += sub_ticker_lst\n",
        "\n",
        "    \n",
        "    #Write crashes to file       \n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(\"\\n\".join(non_collected_tickers))\n",
        "    \n",
        "    #Save last data if there are rests\n",
        "    for key in name_to_index:\n",
        "            break\n",
        "            if dfs[key] != []:\n",
        "                df = pd.concat(dfs[key], axis=0)\n",
        "\n",
        "                df = df.reset_index()\n",
        "\n",
        "                #wtfffff\n",
        "                df.to_feather(f\"{file_name}_save={len(partioned_lst_of_tickers)}_type={key}.feather\")\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be13dc1a",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "14c98fcbbd714afdafb720283540c4a8"
          ]
        },
        "id": "be13dc1a",
        "outputId": "8b621c74-8865-4511-a1f5-2977a7936163"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14c98fcbbd714afdafb720283540c4a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "saving loop:   0%|          | 0/2067 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "save_toggle = True\n",
        "\n",
        "file_name = \"C:/Users/kjartkra/Untitled Folder/stock_data/global_oil\"\n",
        "if save_toggle: \n",
        "    save_data(file_name, 2, lst_of_tickers, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec825654",
      "metadata": {
        "id": "ec825654"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e066a7f",
      "metadata": {
        "scrolled": true,
        "id": "8e066a7f"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "files = glob.glob(\"C:/Users/kjartkra/Untitled Folder/test_saves/*.feather\")\n",
        "dfs = []\n",
        "for file in files:\n",
        "    dfs.append(pd.read_feather(file).set_index(\"index\"))\n",
        "\n",
        "df_big = pd.concat(dfs,axis=0).reset_index()\n",
        "\n",
        "df_big"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b7dbf9",
      "metadata": {
        "id": "56b7dbf9"
      },
      "outputs": [],
      "source": [
        "time_series_df_2, meta_df, fundamental_df, broker_df = get_data(lst_of_tickers[:5], params)\n",
        "time_series_df_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b50e0e",
      "metadata": {
        "id": "66b50e0e"
      },
      "outputs": [],
      "source": [
        "time_series_df_2[\"Number Of Stocks\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4657359",
      "metadata": {
        "id": "a4657359"
      },
      "outputs": [],
      "source": [
        "time_series_df[\"Common Shares - Outstanding - Total\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab00243",
      "metadata": {
        "id": "5ab00243"
      },
      "outputs": [],
      "source": [
        "time_series_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5d3c81",
      "metadata": {
        "id": "5a5d3c81"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "time_series_df.to_excel(\"stock_data_2.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69540527",
      "metadata": {
        "id": "69540527"
      },
      "outputs": [],
      "source": [
        "#Conclusion, makes small difference in time to process at server\n",
        "test_time = False\n",
        "\n",
        "if test_time: \n",
        "    params_single = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ','Period': 'FQ0'}\n",
        "    params_curn = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ','Period': 'FQ0', \"Curn\":\"USD\"}\n",
        "    \n",
        "    \n",
        "    start_time = time.time()\n",
        "    data,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params_single)\n",
        "    print(\"--- simple: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    data_usd,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params_curn)\n",
        "    print(\"--- Curn: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    data_all,err = ek.get_data(osbx_companies.index[:3].to_list(), financials, params)\n",
        "    print(\"--- Scale & Curn: %s seconds ---\" % (time.time() - start_time))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "data_collection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}