{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_nn_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/npmf/blob/main/notebooks/preprocess_nn_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "d8F5tl4NL7FZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kernel setup"
      ],
      "metadata": {
        "id": "Rwo44VGZLhAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "hKuFzk7aEmB9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "!git clone https://github.com/Krankile/npmf.git"
      ],
      "metadata": {
        "id": "91KPY7q0LUOw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://wandb.ai/authorize\n",
        "!wandb login "
      ],
      "metadata": {
        "id": "gUXnibj8YEi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efe8018-9d95-476a-e5d7-cc9dbcf3eaa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##General setup"
      ],
      "metadata": {
        "id": "CLAlA0htLgMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!cd npmf && git pull\n",
        "\n",
        "import math\n",
        "import multiprocessing\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import asdict, dataclass\n",
        "from datetime import datetime, timedelta\n",
        "from operator import itemgetter\n",
        "from typing import Callable, List, Tuple\n",
        "from functools import partial\n",
        "from glob import glob\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "\n",
        "from more_itertools import chunked\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from npmf.utils import Problem\n",
        "from npmf.utils.colors import main, main2, main3\n",
        "from npmf.utils.dataset import EraDataset, EraController\n",
        "from npmf.utils.dtypes import fundamental_types\n",
        "from npmf.utils.eikon import column_mapping\n",
        "from npmf.utils.tests.utils import pickle_df\n",
        "from npmf.utils.wandb import get_datasets, put_dataset, put_nn_model, get_processed_data\n",
        "from npmf.utils.training import EarlyStop, to_device, TqdmPostFix, loss_fns, get_naive_pred\n",
        "from npmf.utils.models import models\n",
        "\n",
        "from numpy.ma.core import outerproduct\n",
        "from pandas.tseries.offsets import BDay, Day\n",
        "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "\n",
        "import wandb as wb"
      ],
      "metadata": {
        "id": "1QSlgObXLq1p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.seterr(all=\"raise\")\n",
        "\n",
        "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[main, main2, main3, \"black\"])\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)  # (6, 4) is default and used in the paper"
      ],
      "metadata": {
        "id": "hkTjKKLmLvpl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqy02oAvY7GM",
        "outputId": "628b803c-a454-424a-a8c8-45080206f758"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(69)"
      ],
      "metadata": {
        "id": "YVFtfDk0pYtd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Get some data"
      ],
      "metadata": {
        "id": "PGuFgO6jHPWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "reload_data = True\n",
        "\n",
        "if reload_data or not \"stock_df\" in vars():\n",
        "    names = [\"stock-data:final\", \"fundamental-data:final\", \"meta-data:final\", \"macro-data:final\"]\n",
        "\n",
        "    stock_df, fundamental_df, meta_df, macro_df = get_datasets(names=names, project=\"master\")\n",
        "\n",
        "    stock_df = stock_df.drop(columns=[\"close_price\", \"currency\"]).astype({\"market_cap\": np.float32})\n",
        "    fundamental_df = fundamental_df.drop(columns=\"period_end_date\").astype(fundamental_types)\n",
        "    macro_df.iloc[:, 1:] = macro_df.iloc[:, 1:].astype(np.float32)"
      ],
      "metadata": {
        "id": "GHmOVxnnHYU_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(config, project=\"master\"):\n",
        "    if not os.path.exists('era_datasets'):\n",
        "        os.makedirs('era_datasets')\n",
        "\n",
        "    with wb.init(\"dataprocessing\", project=project, config=config) as run:\n",
        "        conf = run.config\n",
        "\n",
        "        dates = pd.date_range(start=conf.start_date, end=conf.end_date, freq=\"M\")\n",
        "\n",
        "        for date in TqdmPostFix(dates):\n",
        "            data = EraDataset(current_time=date, stock_df=stock_df, fundamental_df=fundamental_df, meta_df=meta_df, macro_df=macro_df, **conf)\n",
        "\n",
        "            with open(f\"era_datasets/{date}\", \"wb\") as f:\n",
        "                pickle.dump(data, f)\n",
        "        \n",
        "        artname = \"era-dataset-target-minmax\"\n",
        "\n",
        "        art = wb.Artifact(artname, \"dataset\", metadata=conf.as_dict())\n",
        "\n",
        "        art.add_dir(\"./era_datasets\")\n",
        "\n",
        "        run.log_artifact(art)"
      ],
      "metadata": {
        "id": "bpE3uLKSAAt6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, params):\n",
        "    meta_cont_len = 1\n",
        "    meta_cat_len = np.array([len(meta_df[col].unique()) for col in meta_df.iloc[:,1:] if col != \"founding_year\"]) + 1\n",
        "    \n",
        "    stock_feats = 1\n",
        "    macro_feats = (macro_df.shape[1]-1)\n",
        "    funda_feats = (fundamental_df.loc[:,\"revenue\":].shape[1] - 1) + 2\n",
        "\n",
        "    n_features = stock_feats + macro_feats + funda_feats\n",
        "\n",
        "    if params.get(\"feature_subset\") is not None:\n",
        "        n_features = len(params[\"feature_subset\"])\n",
        "\n",
        "    data_given_params = dict(\n",
        "        meta_cont_lens=(meta_cont_len, 1),\n",
        "        meta_cat_lens=list(map(lambda x: (x, int(math.ceil(x**0.25))), meta_cat_len)),\n",
        "        out_len=1 if params[\"forecast_problem\"] == forecast_problem.name else params[\"forecast_w\"],\n",
        "        input_size=n_features,\n",
        "    )\n",
        "\n",
        "    return data_given_params"
      ],
      "metadata": {
        "id": "YLTI-AhSKT6y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_problem = Problem.volatility\n",
        "\n",
        "params_human = dict(\n",
        "    forecast_problem=forecast_problem.name,\n",
        "\n",
        "    cpus=1,\n",
        "    training_w=240*2,\n",
        "    forecast_w=240,\n",
        "    start_date=\"2001-12-31\",\n",
        "    end_date=\"2021-03-31\",\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "params_from_data = get_params_from_data(stock_df, fundamental_df, meta_df, macro_df, {**params_human})\n",
        "\n",
        "config = {  \n",
        "    **params_human,\n",
        "    **params_from_data,\n",
        "}"
      ],
      "metadata": {
        "id": "isJET98vKT6z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_data(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "xFmTA9vuE-2G",
        "outputId": "ca333184-3506-4549-9d7d-c11d1d54702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220609_155437-2mwhr6ac</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/krankile/master/runs/2mwhr6ac\" target=\"_blank\">lyric-butterfly-1465</a></strong> to <a href=\"https://wandb.ai/krankile/master\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 84/232 [25:13<54:56, 22.27s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In case an escape hatch is needed"
      ],
      "metadata": {
        "id": "iu1OfISRvsgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir era_datasets\n",
        "!cp artifacts/era-datasets\\:v2/* era_datasets"
      ],
      "metadata": {
        "id": "GWdj_04UaK38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf era_datasets"
      ],
      "metadata": {
        "id": "GVxFXynaQLQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aFxXvAZTC4EN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}